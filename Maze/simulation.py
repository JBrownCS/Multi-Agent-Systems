# Launch the Simulation
import numpy as np

# Import stable_baselines for machine learning model training
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.ppo import PPO


from MazeEnv import MazeEnv

'''
maze can be changed to add apples to find
'''
world = np.array([[-1, -1, -1, -1, -1, -1, -1, -1, -1],
                      [-1, 1, 0, 0, 0, 0, 2, 0, -1],
                      [-1, 0, 0, 12, 0, 0, 0, 0, -1],
                      [-1, 0, 0, 0, 0, 0, 0, 0, -1],
                      [-1, 0, 0, 0, 0, 0, 12, 0, -1],
                      [-1, 0, 0, 0, 13, 0, 0, 0, -1],
                      [-1, -1, -1, -1, -1, -1, -1, -1, -1]])

#CSGO Dusk 2
World2 = [
    "BBB******************BBBBBB"
    "B*BBBBBBBBBBBBBBBBBBB*****B",
    "B***********************3*B",
    "B**BBBBBBBB***BBBBBBB*BBB*x",
    "B*B*******B***B*****B*B*B*x",
    "B*BBBBBBBBB***BBBBBBB*B*B*x",
    "B*********************B*B*x",
    "BB*BBBB*******BBBBBBBBBB**x",
    "B***BBB******B*******B****x",
    "X*****Bxxxxx*BBBBBBBBB*B**x",
    "X***********5**********BBBB",
    "Xxxxxxxxxxxx5xxxxxxxxxxxxxx"
]
# 10x25, can change to 20x20
world2 = np.array(
    [
        [-1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1],
        [-1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, -1],
        [-1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, -1],
        [-1, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1],
        [-1, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, -1, 0, 0, 0, 0, 0, -1, 0, -1, 0, -1, 0, -1],
        [-1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, -1, 0, -1],
        [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, -1],
        [-1, -1, 0, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1],
        [-1, 0, 0, 0, -1, -1, -1, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1],
        [-1, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, 0, 0, -1],
        [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1],
        [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
    ]
)
# COD 4 Modern Warfare KillingHouse
World3 = [
    "XXXXXXXXXXX",
    "X000000000X",
    "XXX000000XX",
    "X0000XX000X",
    "X000XXXX00X",
    "XX000000X0X",
    "X0330000X0X",
    "X0033000X0X",
    "X000000000X",
    "XXX00XXX00X",
    "X000000000X",
    "XXXXXXXXXXX"
]
world3 = np.array([
        [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
        [-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, -1],
        [-1, -1, -1, 0, 0, 0, 0, 0, 0, 0, -1, -1],
        [-1, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0, -1],
        [-1, 0, 0, 0, -1, -1, -1, -1, 0, 0, 0, -1],
        [-1, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1],
        [-1, 0, 0, 12, 0, 0, 0, 0, 0, -1, 0, -1],
        [-1, 0, 0, 0, 12, 0, 0, 0, 0, -1, 0, -1],
        [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1],
        [-1, -1, -1, 0, 0, 0, -1, -1, -1, 0, 0, -1],
        [-1, 0, 0, 0, 0, 0, 13, 0, 0, 0, 0, -1],
        [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
    ])

# Halo 3 SandTrap (15x15)
World4 = [
    "XXXXXXXXXXXXXXXX",
    "X---XXXXXXX----X",
    "X-X-X-X-X-X--X-X",
    "X-----X-X------X",
    "X--------------X",
    "X-X-XXX-X----X-X",
    "X-X-X-X-X------X",
    "X-X-X-X-X------X",
    "X-X-X-X-X------X",
    "X-X-XXX-X------X",
    "X-X-----X----X-X",
    "X-X-XXX-X------X",
    "X--------------X",
    "X--------------X",
    "X-----X--X-----X",
    "XXXXXXXXXXXXXXXX"
]

world4 = np.array([
    [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
    [-1, 1, 2, 3, -1, -1, -1, -1, -1, -1, -1, 5, 6, 7, 8, -1],
    [-1, 0, -1, 0, -1, 0, -1, 4, -1, 0, -1, 0, 0, -1, 0, -1],
    [-1, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, -1],
    [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1],
    [-1, 0, -1, 0, -1, -1, -1, 0, -1, 0, 0, 0, 0, -1, 0, -1],
    [-1, 0, -1, 0, -1, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, -1],
    [-1, 12, -1, 0, -1, 0, -1, 0, -1, 0, 0, 12, 0, 0, 0, -1],
    [-1, 0, -1, 0, -1, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, -1],
    [-1, 0, -1, 0, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, -1],
    [-1, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, -1, 0, -1],
    [-1, 0, -1, 0, -1, -1, -1, 0, -1, 0, 0, 0, 0, 0, 0, -1],
    [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1],
    [-1, 0, 0, 0, 0, 0, -1, 0, 0, -1, 0, 0, 0, 0, 0, -1],
    [-1, 0, 0, 12, 0, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, -1],
    [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
])
# Battlefield 4  Golmund Railway (20x20)
World5 = [
    "000XXXXXXXXXX000000000",

    "00X000000000X0000000000",
    "00X00000000000X0000000",
    "00X000000000000X000000",
    "00X0000000000000X00000",
    "00X00000000000000X0000",
    "00X000000000000000X000",
    "00X0000000000000000X00",
    "00X00000000000000000X0",
    "00X00000000000000000X0",
    "0X000000000000000000X0",
    "0X000000000000000000X0",
    "X00000000000000000000X",
    "X00000000000000000000X",
    "0X000000000000000000X0",
    "0X00000000000000000X00",
    "00X000000000000000X000",
    "000X000000000000XX0000",
    "00000X000000000X000000",
    "0000000X000000X0000000",

    "00000000XXXXXX00000000"
]
world5 = np.array(
    [
        [0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, -1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
        [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0],
        [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0],
        [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0],
        [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0],
        [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],
        [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],
        [0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],
        [0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],
        [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1],
        [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1],
        [0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],
        [0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0],
        [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0],
        [0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 0],
        [0, 0, 0, 0, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 13, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 13, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0]
    ]
)

#Create the model
env = DummyVecEnv([lambda: MazeEnv(world, numOfAgents=2)])

model = PPO('MlpPolicy', env, learning_rate=0.01)
model.learn(total_timesteps=5000)


numTotalEpisodes = 101
numPredictEpisode = 1

timesSuccessful = 0
while numPredictEpisode < numTotalEpisodes:
    print("--------- STARTING PREDICTIONS -------------")
    state = env.reset()
    done = False
    score = 0

    while not done:
        #Model makes prediction
        action, _state = model.predict(state)
        # Actions are taken and return values
        observation,reward,done,n_state = env.step(action)
        #Adds the reward to the score
        score+=reward
    print(f"Episode:{numPredictEpisode} Score:{score}")
    if score > 0:
        timesSuccessful+= 1
    numPredictEpisode += 1

print(f"Percent Successful: {timesSuccessful}")
